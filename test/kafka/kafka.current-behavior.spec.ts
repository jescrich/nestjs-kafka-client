import { Test } from '@nestjs/testing';
import { Logger } from '@nestjs/common';
import { KafkaClient } from '../../src/kafka/kafka.client';
import { IEventHandler } from '../../src/kafka/kafka.event.handler';
import { setTimeout } from 'timers/promises';
import { randomUUID } from 'crypto';
import { Kafka, Producer } from 'kafkajs';

/**
 * Current Behavior Documentation Tests
 * 
 * These tests document the ACTUAL current behavior of the Kafka implementation
 * as it runs in production, including any bugs or issues.
 * 
 * Purpose: 
 * - Document current behavior (good and bad)
 * - Identify what actually works vs what's broken
 * - Provide baseline for future improvements
 * - Show real production behavior patterns
 */

describe('Kafka Current Behavior Documentation', () => {
  jest.setTimeout(30000);
  
  let kafkaClient: KafkaClient;
  let testKafka: Kafka;
  let testProducer: Producer;
  
  const TEST_BROKERS = process.env.TEST_KAFKA_BROKERS || 'localhost:29092';
  const TEST_TOPIC = `current-behavior-${randomUUID()}`;
  
  // Track what actually happens (not what should happen)
  let actualHandlerCalls: any[] = [];
  let actualBatchCalls: any[] = [];
  let actualErrors: any[] = [];
  let kafkaLogs: any[] = [];

  beforeAll(async () => {
    if (!process.env.TEST_KAFKA_BROKERS && !await isKafkaAvailable()) {
      console.warn(`‚ö†Ô∏è  Skipping current behavior tests - Kafka not available at ${TEST_BROKERS}`);
      return;
    }

    try {
      testKafka = new Kafka({
        clientId: 'current-behavior-test',
        brokers: [TEST_BROKERS],
        logLevel: 0,
      });
      
      testProducer = testKafka.producer();
      await testProducer.connect();
      
      // Create topic
      const admin = testKafka.admin();
      await admin.connect();
      await admin.createTopics({
        topics: [{ topic: TEST_TOPIC, numPartitions: 1 }]
      });
      await admin.disconnect();
      
    } catch (error) {
      console.warn(`‚ö†Ô∏è  Could not setup Kafka for current behavior tests: ${error.message}`);
    }
  });

  beforeEach(() => {
    actualHandlerCalls = [];
    actualBatchCalls = [];
    actualErrors = [];
    kafkaLogs = [];
    
    // Capture console logs to understand what's happening
    const originalConsoleError = console.error;
    const originalConsoleWarn = console.warn;
    
    console.error = (...args) => {
      kafkaLogs.push({ level: 'ERROR', message: args.join(' '), timestamp: Date.now() });
      originalConsoleError(...args);
    };
    
    console.warn = (...args) => {
      kafkaLogs.push({ level: 'WARN', message: args.join(' '), timestamp: Date.now() });
      originalConsoleWarn(...args);
    };
  });

  afterEach(async () => {
    try {
      await kafkaClient?.shutdown();
    } catch (error) {
      // Document shutdown issues
      actualErrors.push({ type: 'shutdown', error: error.message });
    }
    
    // Restore console
    console.error = console.error;
    console.warn = console.warn;
  });

  afterAll(async () => {
    try {
      await testProducer?.disconnect();
      
      const admin = testKafka.admin();
      await admin.connect();
      await admin.deleteTopics({ topics: [TEST_TOPIC] });
      await admin.disconnect();
    } catch (error) {
      console.warn('Cleanup error:', error.message);
    }
  });

  // Helper to check if Kafka is available
  async function isKafkaAvailable(): Promise<boolean> {
    try {
      const testClient = new Kafka({
        clientId: 'availability-test',
        brokers: [TEST_BROKERS],
        logLevel: 0,
      });
      
      const admin = testClient.admin();
      await admin.connect();
      await admin.disconnect();
      return true;
    } catch {
      return false;
    }
  }

  describe('üìä Current Production Behavior Documentation', () => {
    it('should document what actually happens when processing messages', async () => {
      if (!testKafka) return;

      // Simple handler that just records what happens
      class ObservingHandler implements IEventHandler<any> {
        async handle({ key, event, payload }: { key: string; event: any; payload: any }): Promise<void> {
          actualHandlerCalls.push({
            method: 'handle',
            key,
            event,
            offset: payload?.offset,
            timestamp: Date.now()
          });
        }

        async handleBatch({ key, events, payloads }: { key: string; events: any[]; payloads: any[] }): Promise<void> {
          actualBatchCalls.push({
            method: 'handleBatch',
            key,
            eventCount: events.length,
            events,
            timestamp: Date.now()
          });
        }
      }

      try {
        kafkaClient = new KafkaClient(
          `behavior-test-${randomUUID()}`,
          TEST_BROKERS,
          {
            maxConcurrency: 1,
            enableCpuMonitoring: false,
            enableMemoryMonitoring: false,
          }
        );
        
        await kafkaClient.onModuleInit();

        // Produce some test messages
        await testProducer.send({
          topic: TEST_TOPIC,
          messages: [
            { key: 'test1', value: JSON.stringify({ id: 1, action: 'test' }) },
            { key: 'test2', value: JSON.stringify({ id: 2, action: 'test' }) },
          ],
        });

        // Start consuming and document what happens
        const startTime = Date.now();
        
        // Note: This might not work as expected - that's what we're documenting
        await kafkaClient.consumeMany([
          { topic: TEST_TOPIC, handler: new ObservingHandler() }
        ], `behavior-group-${randomUUID()}`);

        // Wait and see what actually happens
        await setTimeout(5000);
        
        const endTime = Date.now();
        const metrics = kafkaClient.getMetrics();

        // Document ACTUAL behavior (not expected)
        console.log(`üìä ACTUAL Current Behavior:
          ‚è±Ô∏è  Test Duration: ${endTime - startTime}ms
          üì• Messages Produced: 2
          üîÑ Handle() Calls: ${actualHandlerCalls.length}
          üì¶ HandleBatch() Calls: ${actualBatchCalls.length}
          ‚ùå Errors Captured: ${actualErrors.length}
          üìä KafkaClient Metrics:
            - Consumed Messages: ${metrics.consumedMessages}
            - Produced Messages: ${metrics.producedMessages}
            - Processing Failures: ${metrics.processingFailures}
            - DLQ Messages: ${metrics.dlqMessages}
          üîç Kafka Logs: ${kafkaLogs.length} entries
          üìã Rebalancing Issues: ${kafkaLogs.filter(log => log.message.includes('rebalancing')).length}
        `);

        // Document the actual state - don't assert what should happen
        const totalProcessed = actualHandlerCalls.length + actualBatchCalls.reduce((sum, batch) => sum + batch.eventCount, 0);
        
        if (totalProcessed === 0) {
          console.log('üö® CURRENT ISSUE DOCUMENTED: No messages are being processed by handlers');
          console.log('   - Messages are produced ‚úÖ');
          console.log('   - KafkaClient initializes ‚úÖ');
          console.log('   - Consumer connects ‚úÖ');
          console.log('   - But handlers are never called ‚ùå');
        }

        if (kafkaLogs.some(log => log.message.includes('rebalancing'))) {
          console.log('üö® CURRENT ISSUE DOCUMENTED: Constant rebalancing detected');
        }

        // This test always passes - it just documents current behavior
        expect(true).toBe(true);

      } catch (error) {
        actualErrors.push({ type: 'test_execution', error: error.message, stack: error.stack });
        console.log(`üö® CURRENT ISSUE DOCUMENTED: Test execution failed: ${error.message}`);
        expect(true).toBe(true); // Still pass - we're documenting, not testing
      }
    });

    it('should document the actual DLQ behavior in current production', async () => {
      if (!testKafka) return;

      class AlwaysFailingHandler implements IEventHandler<any> {
        async handle({ key, event }: { key: string; event: any }): Promise<void> {
          actualHandlerCalls.push({ key, event, timestamp: Date.now() });
          throw new Error('Intentional test failure');
        }
      }

      try {
        kafkaClient = new KafkaClient(
          `dlq-behavior-test-${randomUUID()}`,
          TEST_BROKERS,
          {
            messageRetryLimit: 1, // Low for fast testing
            dlqSuffix: '-dlq',
            messageRetryDelayMs: 100,
            enableCpuMonitoring: false,
            enableMemoryMonitoring: false,
          }
        );
        
        await kafkaClient.onModuleInit();

        await testProducer.send({
          topic: TEST_TOPIC,
          messages: [
            { key: 'fail-test', value: JSON.stringify({ id: 1, shouldFail: true }) },
          ],
        });

        await kafkaClient.consumeMany([
          { topic: TEST_TOPIC, handler: new AlwaysFailingHandler() }
        ], `dlq-behavior-group-${randomUUID()}`);

        await setTimeout(3000);
        
        const metrics = kafkaClient.getMetrics();

        console.log(`üìä ACTUAL DLQ Behavior:
          üîÑ Handler Attempts: ${actualHandlerCalls.length}
          üíÄ DLQ Messages (metric): ${metrics.dlqMessages}
          ‚ùå Processing Failures (metric): ${metrics.processingFailures}
          üîÑ Retries (metric): ${metrics.retries}
          üìã Error Logs: ${kafkaLogs.filter(log => log.level === 'ERROR').length}
        `);

        if (actualHandlerCalls.length === 0) {
          console.log('üö® CURRENT DLQ ISSUE: Handler never called, so DLQ logic never triggered');
        } else if (metrics.dlqMessages === 0) {
          console.log('üö® CURRENT DLQ ISSUE: Handler called but messages not sent to DLQ');
        } else {
          console.log('‚úÖ DLQ appears to be working');
        }

        expect(true).toBe(true); // Always pass - documenting behavior

      } catch (error) {
        console.log(`üö® CURRENT DLQ ISSUE: ${error.message}`);
        expect(true).toBe(true);
      }
    });

    it('should document Consumer Module vs direct KafkaClient behavior differences', async () => {
      if (!testKafka) return;

      // Test direct KafkaClient first
      console.log('üîß Testing Direct KafkaClient...');
      
      class DirectTestHandler implements IEventHandler<any> {
        async handle({ key, event }: { key: string; event: any }): Promise<void> {
          actualHandlerCalls.push({ 
            source: 'direct', 
            key, 
            event, 
            timestamp: Date.now() 
          });
        }
      }

      try {
        kafkaClient = new KafkaClient(
          `direct-test-${randomUUID()}`,
          TEST_BROKERS,
          { enableCpuMonitoring: false, enableMemoryMonitoring: false }
        );
        
        await kafkaClient.onModuleInit();

        await testProducer.send({
          topic: TEST_TOPIC,
          messages: [
            { key: 'direct-test', value: JSON.stringify({ source: 'direct', id: 1 }) },
          ],
        });

        await kafkaClient.consumeMany([
          { topic: TEST_TOPIC, handler: new DirectTestHandler() }
        ], `direct-group-${randomUUID()}`);

        await setTimeout(2000);
        
        const directCalls = actualHandlerCalls.filter(call => call.source === 'direct');
        const directMetrics = kafkaClient.getMetrics();

        console.log(`üìä Direct KafkaClient Results:
          üîÑ Handler Calls: ${directCalls.length}
          üìä Metrics - Consumed: ${directMetrics.consumedMessages}
          üìä Metrics - Failures: ${directMetrics.processingFailures}
        `);

        await kafkaClient.shutdown();

      } catch (error) {
        console.log(`üö® Direct KafkaClient Issue: ${error.message}`);
      }

      // Document what we observed
      console.log(`üìã CURRENT BEHAVIOR SUMMARY:
        üîß Direct KafkaClient: ${actualHandlerCalls.filter(c => c.source === 'direct').length} handler calls
        üè¢ Consumer Module: (would test separately)
        üö® Issues Observed: ${actualErrors.length}
        üìä Kafka Logs Generated: ${kafkaLogs.length}
      `);

      expect(true).toBe(true); // Always pass - this is documentation
    });

    it('should document the actual message flow and where it breaks', async () => {
      if (!testKafka) return;

      class DiagnosticHandler implements IEventHandler<any> {
        async handle({ key, event, payload }: { key: string; event: any; payload: any }): Promise<void> {
          actualHandlerCalls.push({
            key,
            event,
            offset: payload?.offset,
            partition: payload?.partition,
            timestamp: Date.now(),
            step: 'handler_called'
          });
          
          console.log(`üîç DIAGNOSTIC: Handler called for key=${key}, event=${JSON.stringify(event)}`);
        }
      }

      try {
        kafkaClient = new KafkaClient(
          `diagnostic-test-${randomUUID()}`,
          TEST_BROKERS,
          {
            maxConcurrency: 1,
            enableCpuMonitoring: false,
            enableMemoryMonitoring: false,
          }
        );

        console.log('üîç DIAGNOSTIC: Initializing KafkaClient...');
        await kafkaClient.onModuleInit();
        console.log('üîç DIAGNOSTIC: KafkaClient initialized');

        console.log('üîç DIAGNOSTIC: Producing test message...');
        await testProducer.send({
          topic: TEST_TOPIC,
          messages: [
            { key: 'diagnostic', value: JSON.stringify({ test: 'diagnostic', id: 1 }) },
          ],
        });
        console.log('üîç DIAGNOSTIC: Message produced');

        console.log('üîç DIAGNOSTIC: Starting consumer...');
        const consumePromise = kafkaClient.consumeMany([
          { topic: TEST_TOPIC, handler: new DiagnosticHandler() }
        ], `diagnostic-group-${randomUUID()}`);
        
        console.log('üîç DIAGNOSTIC: Consumer started, waiting for processing...');
        await setTimeout(3000);
        
        const metrics = kafkaClient.getMetrics();
        
        console.log(`üîç DIAGNOSTIC RESULTS:
          üì• Messages Produced: 1
          üîÑ Handler Calls: ${actualHandlerCalls.length}
          üìä KafkaClient Consumed Metric: ${metrics.consumedMessages}
          üìä KafkaClient Produced Metric: ${metrics.producedMessages}
          üö® Processing Failures: ${metrics.processingFailures}
          üìã Kafka Error Logs: ${kafkaLogs.filter(log => log.level === 'ERROR').length}
          üìã Kafka Warn Logs: ${kafkaLogs.filter(log => log.level === 'WARN').length}
        `);

        // Analyze where the flow breaks
        if (metrics.producedMessages > 0) {
          console.log('‚úÖ Message production: WORKING');
        } else {
          console.log('‚ùå Message production: NOT WORKING');
        }

        if (metrics.consumedMessages > 0) {
          console.log('‚úÖ Message consumption (KafkaJS level): WORKING');
        } else {
          console.log('‚ùå Message consumption (KafkaJS level): NOT WORKING');
        }

        if (actualHandlerCalls.length > 0) {
          console.log('‚úÖ Handler invocation: WORKING');
        } else {
          console.log('‚ùå Handler invocation: NOT WORKING - This is where it breaks!');
        }

        const rebalanceErrors = kafkaLogs.filter(log => 
          log.message.includes('rebalancing') || log.message.includes('REBALANCE')
        ).length;

        if (rebalanceErrors > 0) {
          console.log(`üö® Rebalancing issues detected: ${rebalanceErrors} occurrences`);
        }

      } catch (error) {
        console.log(`üö® DIAGNOSTIC ERROR: ${error.message}`);
        actualErrors.push({ type: 'diagnostic', error: error.message });
      }

      expect(true).toBe(true); // Always pass - this documents current state
    });
  });

  describe('üîß Current Configuration Impact', () => {
    it('should document how different configurations affect current behavior', async () => {
      if (!testKafka) return;

      const configs = [
        { name: 'minimal', options: { maxConcurrency: 1 } },
        { name: 'batch-focused', options: { maxConcurrency: 1, batchSizeMultiplier: 10 } },
        { name: 'high-concurrency', options: { maxConcurrency: 3, batchSizeMultiplier: 5 } },
      ];

      for (const config of configs) {
        console.log(`\nüîß Testing ${config.name} configuration...`);
        
        const configResults = {
          handlerCalls: 0,
          batchCalls: 0,
          errors: 0,
          metrics: null as any
        };

        try {
          const testClient = new KafkaClient(
            `config-test-${config.name}-${randomUUID()}`,
            TEST_BROKERS,
            {
              ...config.options,
              enableCpuMonitoring: false,
              enableMemoryMonitoring: false,
            }
          );

          await testClient.onModuleInit();

          class ConfigTestHandler implements IEventHandler<any> {
            async handle({ key, event }: { key: string; event: any }): Promise<void> {
              configResults.handlerCalls++;
            }
          }

          await testProducer.send({
            topic: TEST_TOPIC,
            messages: [
              { key: config.name, value: JSON.stringify({ config: config.name, test: true }) },
            ],
          });

          await testClient.consumeMany([
            { topic: TEST_TOPIC, handler: new ConfigTestHandler() }
          ], `config-group-${config.name}-${randomUUID()}`);

          await setTimeout(2000);
          
          configResults.metrics = testClient.getMetrics();
          await testClient.shutdown();

        } catch (error) {
          configResults.errors++;
          console.log(`‚ùå ${config.name} config error: ${error.message}`);
        }

        console.log(`üìä ${config.name} Results:
          üîÑ Handler Calls: ${configResults.handlerCalls}
          üìä Consumed (metric): ${configResults.metrics?.consumedMessages || 0}
          ‚ùå Errors: ${configResults.errors}
        `);
      }

      expect(true).toBe(true); // Document findings
    });
  });
});


